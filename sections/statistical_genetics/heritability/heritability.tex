\documentclass[12pt]{article}

% loads config.sty
\makeatletter
\def\input@path{{../../../}}
\makeatother
\usepackage{config}
\usepackage{macros}

\title{Heritability}
\date{\today}

\begin{document}

\maketitle

\section{SNP Heritability}
These derivations are based on the Methods of [\href{https://www.nature.com/articles/ng.608}{Yang et al., 2010}]. 

\subsection{Phenotype model}
We can define a quantitative phenotype $y$ as:
$$ \by = \bX_c \bbeta + \bepsilon $$

Where:
\begin{itemize}
    \item $\by$: phenotypes.
    $N \times 1$ vector.
    Centered so that $\E[\by]=0$.
    \begin{itemize}
        \item $N$: number of samples.
    \end{itemize}
    \item $\bX_c$: normalized genotypes for causal variants.
    $N \times M_c$ matrix.
    \begin{itemize}
        \item $M_c$: number of causal variants.
        \item Normalized according to
        $\bX_{c,i} = \frac{\bX'_{c,i} - 2 f_i}{\sqrt{2 f_i (1 - f_i)}}$.
        \begin{itemize}
            \item $\bX_c'$: allele dosages, taking on values of 0, 1, 2.
            \item $f_i$: true population allele frequency for variant $i$.
            \item Such that for each row (variant), $\E[\bX_{c,i}] = 0$ and $\Var[\bX_{c,i}] = 1$.
        \end{itemize}
    \end{itemize}
    \item $\bbeta$: per-normalized-genotype causal effects.
    $M_c \times 1$ vector.
    \begin{itemize}
        \item Assume infinitesimal model.
        \item Drawn from $\bbeta \sim \N(\B{0}, \bI \sigma_{\beta}^2)$.
        \begin{itemize}
            \item $\bI$: $M_c \times M_c$ identity matrix.
            \item $\sigma_{\beta}^2$: variance of causal effects.
        \end{itemize}
    \end{itemize}
    \item $\bepsilon$: residual effects (i.e. error or noise term). $N \times 1$ vector.
    \begin{itemize}
        \item Drawn from $\bepsilon \sim \N(0, \bI \vareps)$.
        \begin{itemize}
            \item $\bI$: $N \times N$ identity matrix.
            \item $\vareps$: residual variance.
        \end{itemize}
    \end{itemize}
\end{itemize}
We assume $\bX_c$, $\bbeta$, and $\bepsilon$ are all independent from each other.
We can define the genetic effects as a single term, $\bg = \bX_c \bbeta$, meaning that:
\begin{equation*}
\by = \bg + \bepsilon
\quad\mathrm{where}\quad
\bg \sim \N(0, I \varg)
\quad\mathrm{where}\quad
\varg = M_c \sigma_{\beta}^2
\end{equation*}
We interpret $\varg$ as variance of total additive genetic effects on the phenotype.

\subsection{Variance of the phenotype}
By making use of the independence between terms, we can define the variance-covariance matrix of $\by$ as:
\begin{align*}
    \Var[\by] &= \Var[\bX_c \bbeta + \bepsilon] \\
    &= \Var[\bX_c] \Var[\bbeta] + \Var[\bepsilon] \\
    &= (\bX_c \bX_c^{\T}) \varg + \bI \vareps \\
    &= (\bX_c \bX_c^{\T}) \frac{\varg}{M_c} + \bI \vareps \\
    &= \bG \varg + \bI \vareps \\
\end{align*}
Where we define $\bG = \frac{\bX_c \bX_c^{\T}}{M_c}$ as the $N \times N$ genetic relationship matrix (GRM) between individuals.
The $G_{ii}$ element is the variance of individual $i$'s normalized genotype vector, while the $G_{ij}$ element is the covariance of individuals $i$ and $j$'s normalized genotype vectors.

Narrow-sense heritability is defined as the proportion of phenotypic variance, $\sigma_P^2$, explained by additive genetic effects:
$$ h^2 = \frac{\varg}{\sigma_P^2} = \frac{\varg}{\varg + \vareps} $$

\subsection{Estimating the GRM}

In practice, we likely do not know the exact set of causal variants and instead must estimate the GRM using a set of genotyped SNPs:

$$ \bA = \frac{\bX \bX^{\T}}{M} $$

Where $\bA$ is the estimated GRM, $X$ is the normalized genotype matrix of our genotyped SNPs, and $M$ is the number of genotyped SNPs.
Note that because we are also working with a sample, $X$ is normalized using sample allele frequencies, $\bp$:

$$ \bX_i = \frac{\bX'_i - 2 p_i}{\sqrt{2 p_i (1 - p_i)}} $$

However, this equation for $A$ ignores the sampling error associated with each SNP.
Let's consider the covariance computation between two individuals for SNP $i$, which is then summed across $M$ SNPs to get the value for $A_{jk}$.
When $j \neq k$:
\begin{align*}
    A_{ijk} &= x_{ij} x_{ik} \\
    &= \frac{x'_{ij} - 2 p_i}{\sqrt{2 p_i (1 - p_i)}}
    \frac{x'_{ik} - 2 p_i}{\sqrt{2 p_i (1 - p_i)}} \\
    &= \frac{(x'_{ij} - 2 p_i)(x'_{ik} - 2 p_i)}{2 p_i (1 - p_i)}
\end{align*}
Because $x'_{ij}$ and $x'_{ik}$ are independent from each other and $p_i$ is a constant:
\begin{align*}
    \Var[A_{ijk}] &= \Var[\frac{(x'_{ij} - 2 p_i)(x'_{ik} - 2 p_i)}{2 p_i (1 - p_i)}] \\
    &= \frac{\Var[(x'_{ij} - 2 p_i)]\Var[(x'_{ik} - 2 p_i)]}{(2 p_i (1 - p_i))^2} \\
    &= \frac{\Var[(x'_{ij})]\Var[(x'_{ik})]}{(2 p_i (1 - p_i))^2} \\
    &= \frac{(2 p_i (2 - p_i))(2 p_i (2 - p_i))}{(2 p_i (1 - p_i))^2} \\
    &= 1
\end{align*}
So, the variance in $A_{jk}$ is independent of allele frequency. But this is not the case when $j = k$:
\begin{align*}
    A_{ijj} &= x_{ij}^2 \\
    &= (\frac{x'_{ij} - 2 p_i}{\sqrt{2 p_i (1 - p_i)}})^2 \\
    &= \frac{(x'_{ij} - 2 p_i)^2}{2 p_i (1 - p_i)}
\end{align*}
For simplicity, let's denote $Z = 2 p_i (1 - p_i)$ and make use of $\Var[Y] = \E[Y^2] - \E[Y]^2$:
\begin{align*}
    \Var[A_{ijj}] &= \Var[\frac{(x'_{ij} - 2 p_i)^2}{Z}] \\
    &= \frac{\Var[(x'_{ij} - 2 p_i)^2]}{(Z)^2} \\
    &= \frac{\E[((x'_{ij} - 2 p_i)^2)^2] - \E[(x'_{ij} - 2 p_i)^2)]^2}{(Z)^2} \\
    &= \frac{(Z) - (Z)^2}{(Z)^2} \\
    &= \frac{(Z)(1  - Z)}{(Z)^2} \\
    &= \frac{1  - Z}{Z} \\
    &= \frac{1  - 2 p_i (1 - p_i)}{2 p_i (1 - p_i)} \\
\end{align*}
The full derivation for why $\E[((x'_{ij} - 2 p_i)^2)^2] = \E[(x'_{ij} - 2 p_i)^2] = 2 p_i (1 - p_i)$ is very lengthy algebraically, but can be shortcutted by using the formula for the \href{https://en.wikipedia.org/wiki/Binomial_distribution#Higher_moments}{higher moments of a binomially distributed variable}, where $n=2$ and $p=p_i$.
Importantly, the variance of $A_{jj}$ therefore depends on the allele frequencies of the SNPs, even after normalization.

\end{document}